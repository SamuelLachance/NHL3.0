{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1-pqA92afDz4kmbE1bat_kX2EA8EJXHyo",
      "authorship_tag": "ABX9TyNcd8buMtXXaBZJaHp+gBk/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SamuelLachance/NHL3.0/blob/main/TwitterTrends.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBRiqDGTj5NG",
        "outputId": "2211cad7-3829-4a50-ed43-c46761b889dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Carolina Hurricanes vs New York Rangers:\n",
            "Score_A : [2.91063333] Win%: [53.16597444]\n",
            "Score_H : [2.5639834] Win%: [46.83402556]\n",
            "Total: [5.47461674]\n",
            "Twitter_A : 68.29268292682927 %\n",
            "Twitter_H : 78.65168539325843 %\n",
            "Columbus Blue Jackets vs Washington Capitals:\n",
            "Score_A : [3.23065] Win%: [49.4325504]\n",
            "Score_H : [3.30482101] Win%: [50.5674496]\n",
            "Total: [6.535471]\n",
            "Twitter_A : 76.31578947368422 %\n",
            "Twitter_H : 83.5820895522388 %\n",
            "Florida Panthers vs Philadelphia Flyers:\n",
            "Score_A : [3.43497595] Win%: [58.09965765]\n",
            "Score_H : [2.47723781] Win%: [41.90034235]\n",
            "Total: [5.91221376]\n",
            "Twitter_A : 77.77777777777779 %\n",
            "Twitter_H : 63.26530612244898 %\n",
            "Minnesota Wild vs New Jersey Devils:\n",
            "Score_A : [2.75521501] Win%: [46.68463965]\n",
            "Score_H : [3.14654418] Win%: [53.31536035]\n",
            "Total: [5.90175919]\n",
            "Twitter_A : 89.58333333333334 %\n",
            "Twitter_H : 88.42105263157895 %\n",
            "Nashville Predators vs Buffalo Sabres:\n",
            "Score_A : [2.96818181] Win%: [50.46958128]\n",
            "Score_H : [2.91294844] Win%: [49.53041872]\n",
            "Total: [5.88113025]\n",
            "Twitter_A : 76.0 %\n",
            "Twitter_H : 62.5 %\n",
            "Ottawa Senators vs Boston Bruins:\n",
            "Score_A : [2.80413226] Win%: [44.173132]\n",
            "Score_H : [3.54391718] Win%: [55.826868]\n",
            "Total: [6.34804944]\n",
            "Twitter_A : 80.64516129032258 %\n",
            "Twitter_H : 79.36507936507937 %\n",
            "Tampa Bay Lightning vs Montréal Canadiens:\n",
            "Score_A : [3.1544544] Win%: [56.32312382]\n",
            "Score_H : [2.44618382] Win%: [43.67687618]\n",
            "Total: [5.60063822]\n",
            "Twitter_A : 73.68421052631578 %\n",
            "Twitter_H : 81.81818181818183 %\n",
            "Toronto Maple Leafs vs New York Islanders:\n",
            "Score_A : [2.49519197] Win%: [46.25227212]\n",
            "Score_H : [2.89955267] Win%: [53.74772788]\n",
            "Total: [5.39474465]\n",
            "Twitter_A : 59.25925925925925 %\n",
            "Twitter_H : 67.56756756756756 %\n",
            "Arizona Coyotes vs Winnipeg Jets:\n",
            "Score_A : [2.68306876] Win%: [45.78403053]\n",
            "Score_H : [3.17720332] Win%: [54.21596947]\n",
            "Total: [5.86027208]\n",
            "Twitter_A : 84.375 %\n",
            "Twitter_H : 86.15384615384616 %\n",
            "Detroit Red Wings vs St. Louis Blues:\n",
            "Score_A : [2.86152818] Win%: [49.74021947]\n",
            "Score_H : [2.89141825] Win%: [50.25978053]\n",
            "Total: [5.75294642]\n",
            "Twitter_A : 79.3103448275862 %\n",
            "Twitter_H : 83.92857142857143 %\n",
            "Seattle Kraken vs Dallas Stars:\n",
            "Score_A : [2.78862889] Win%: [47.77791251]\n",
            "Score_H : [3.04801977] Win%: [52.22208749]\n",
            "Total: [5.83664866]\n",
            "Twitter_A : 85.71428571428571 %\n",
            "Twitter_H : 87.3015873015873 %\n",
            "Calgary Flames vs Anaheim Ducks:\n",
            "Score_A : [3.06509494] Win%: [54.70121507]\n",
            "Score_H : [2.53824483] Win%: [45.29878493]\n",
            "Total: [5.60333977]\n",
            "Twitter_A : 70.96774193548387 %\n",
            "Twitter_H : 75.92592592592592 %\n",
            "Vegas Golden Knights vs Vancouver Canucks:\n",
            "Score_A : [2.92166312] Win%: [48.05444349]\n",
            "Score_H : [3.15823898] Win%: [51.94555651]\n",
            "Total: [6.0799021]\n",
            "Twitter_A : 97.5609756097561 %\n",
            "Twitter_H : 85.13513513513513 %\n"
          ]
        }
      ],
      "source": [
        "from optparse import OptionContainer\n",
        "from textblob.en.np_extractors import filter_insignificant\n",
        "from http.cookiejar import LoadError\n",
        "import os\n",
        "import requests\n",
        "from textblob import TextBlob\n",
        "import datetime\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "import pickle\n",
        "import time\n",
        "import random\n",
        "import json\n",
        "import unicodedata\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "#remove accents\n",
        "\n",
        "def remove_accents(input_str):\n",
        "    nfkd_form = unicodedata.normalize('NFKD', input_str)\n",
        "    only_ascii = nfkd_form.encode('ASCII', 'ignore')\n",
        "    return only_ascii\n",
        "\n",
        "def weird_division(x,y):\n",
        "    if y == 0:\n",
        "        return 0\n",
        "    return x / y\n",
        "\n",
        "#get the time\n",
        "yesterday = (datetime.date.today()- datetime.timedelta(days=1)).strftime('%Y-%m-%d')\n",
        "today = datetime.date.today().strftime('%Y-%m-%d')\n",
        "year = 20222023\n",
        "\n",
        "urlNHL = 'https://www.naturalstattrick.com/teamtable.php?fromseason=20222023&thruseason=20222023&stype=2&sit=sva&score=all&rate=y&team=all&loc=B&gpf=c&gp=10&fd=&td='\n",
        "req = requests.get(urlNHL)\n",
        "\n",
        "soup = BeautifulSoup(req.content)\n",
        "\n",
        "top = list(soup.children)\n",
        "\n",
        "body = soup.find('body')\n",
        "\n",
        "body.find_all('th')\n",
        "\n",
        "columns = [item.text for item in body.find_all('th')]\n",
        "columns\n",
        "\n",
        "body.find_all('td')\n",
        "\n",
        "data = [e.text for e in body.find_all('td')]\n",
        "\n",
        "start = 0\n",
        "table= []\n",
        "\n",
        "#loop through entire data\n",
        "\n",
        "while start+len(columns) <= len(data):\n",
        "    player = []\n",
        "    #use length of columns as iteration stop point to get list of info for 1 player \n",
        "    for i in range(start,start+len(columns)):\n",
        "        player.append(data[i])\n",
        "    #add player row to list\n",
        "    table.append(player)\n",
        "    #start at next player\n",
        "    start += len(columns)\n",
        "\n",
        "df = pd.DataFrame(table, columns = columns, dtype = 'float').set_index('')\n",
        "\n",
        "df.head()\n",
        "\n",
        "urlNHL2 = 'https://www.naturalstattrick.com/teamtable.php?fromseason=20222023&thruseason=20222023&stype=2&sit=pp&score=all&rate=y&team=all&loc=B&gpf=c&gp=10&fd=&td='\n",
        "req2 = requests.get(urlNHL2)\n",
        "\n",
        "soup2 = BeautifulSoup(req2.content)\n",
        "\n",
        "top2 = list(soup2.children)\n",
        "\n",
        "body2 = soup2.find('body')\n",
        "\n",
        "body2.find_all('th')\n",
        "\n",
        "columns2 = [item.text for item in body2.find_all('th')]\n",
        "columns2\n",
        "\n",
        "body2.find_all('td')\n",
        "\n",
        "data2 = [e.text for e in body2.find_all('td')]\n",
        "\n",
        "start2 = 0\n",
        "table2 = []\n",
        "\n",
        "#loop through entire data\n",
        "\n",
        "while start2+len(columns2) <= len(data2):\n",
        "    player = []\n",
        "    #use length of columns as iteration stop point to get list of info for 1 player \n",
        "    for i in range(start2,start2+len(columns2)):\n",
        "        player.append(data2[i])\n",
        "    #add player row to list\n",
        "    table2.append(player)\n",
        "    #start at next player\n",
        "    start2 += len(columns2)\n",
        "\n",
        "df2 = pd.DataFrame(table2, columns = columns2, dtype = 'float').set_index('')\n",
        "\n",
        "df2.head()\n",
        "\n",
        "urlNHL3 = 'https://www.naturalstattrick.com/teamtable.php?fromseason=20222023&thruseason=20222023&stype=2&sit=pk&score=all&rate=y&team=all&loc=B&gpf=c&gp=10&fd=&td='\n",
        "req3 = requests.get(urlNHL3)\n",
        "\n",
        "soup3 = BeautifulSoup(req3.content)\n",
        "\n",
        "top3 = list(soup3.children)\n",
        "\n",
        "body3 = soup3.find('body')\n",
        "\n",
        "body3.find_all('th')\n",
        "\n",
        "columns3 = [item.text for item in body3.find_all('th')]\n",
        "columns3\n",
        "\n",
        "body3.find_all('td')\n",
        "\n",
        "data3 = [e.text for e in body3.find_all('td')]\n",
        "\n",
        "start3 = 0\n",
        "table3 = []\n",
        "while start3+len(columns3) <= len(data3):\n",
        "    player = []\n",
        "    #use length of columns as iteration stop point to get list of info for 1 player \n",
        "    for i in range(start3,start3+len(columns3)):\n",
        "        player.append(data3[i])\n",
        "    #add player row to list\n",
        "    table3.append(player)\n",
        "    #start at next player\n",
        "    start3 += len(columns3)\n",
        "\n",
        "df3 = pd.DataFrame(table3, columns = columns3, dtype = 'float').set_index('')\n",
        "\n",
        "df3.head()\n",
        "\n",
        "urlNHL4 = 'https://www.naturalstattrick.com/teamtable.php?fromseason=20222023&thruseason=20222023&stype=2&sit=sva&score=all&rate=y&team=all&loc=B&gpf=410&gp=10&fd=&td='\n",
        "req4 = requests.get(urlNHL4)\n",
        "\n",
        "soup4 = BeautifulSoup(req4.content)\n",
        "\n",
        "top4 = list(soup4.children)\n",
        "\n",
        "body4 = soup4.find('body')\n",
        "\n",
        "body4.find_all('th')\n",
        "\n",
        "columns4 = [item.text for item in body4.find_all('th')]\n",
        "columns4\n",
        "\n",
        "body4.find_all('td')\n",
        "\n",
        "data4 = [e.text for e in body4.find_all('td')]\n",
        "\n",
        "start4 = 0\n",
        "table4 = []\n",
        "\n",
        "\n",
        "#loop through entire data\n",
        "\n",
        "while start4+len(columns4) <= len(data4):\n",
        "    player = []\n",
        "    #use length of columns as iteration stop point to get list of info for 1 player \n",
        "    for i in range(start4,start4+len(columns4)):\n",
        "        player.append(data4[i])\n",
        "    #add player row to list\n",
        "    table4.append(player)\n",
        "    #start at next player\n",
        "    start4 += len(columns4)\n",
        "\n",
        "df4 = pd.DataFrame(table4, columns = columns4, dtype = 'float').set_index('')\n",
        "\n",
        "df4.head()\n",
        "\n",
        "urlNHL5 = 'https://www.naturalstattrick.com/teamtable.php?fromseason=20222023&thruseason=20222023&stype=2&sit=pp&score=all&rate=y&team=all&loc=B&gpf=410&fd=&td='\n",
        "req5 = requests.get(urlNHL5)\n",
        "\n",
        "soup5 = BeautifulSoup(req5.content)\n",
        "\n",
        "top5 = list(soup5.children)\n",
        "\n",
        "body5 = soup5.find('body')\n",
        "\n",
        "body5.find_all('th')\n",
        "\n",
        "columns5 = [item.text for item in body5.find_all('th')]\n",
        "columns5\n",
        "\n",
        "body5.find_all('td')\n",
        "\n",
        "data5 = [e.text for e in body5.find_all('td')]\n",
        "\n",
        "start5 = 0\n",
        "table5 = []\n",
        "\n",
        "\n",
        "\n",
        "#loop through entire data\n",
        "\n",
        "while start5+len(columns5) <= len(data5):\n",
        "    player = []\n",
        "    #use length of columns as iteration stop point to get list of info for 1 player \n",
        "    for i in range(start5,start5+len(columns5)):\n",
        "        player.append(data5[i])\n",
        "    #add player row to list\n",
        "    table5.append(player)\n",
        "    #start at next player\n",
        "    start5 += len(columns5)\n",
        "\n",
        "df5 = pd.DataFrame(table5, columns = columns5, dtype = 'float').set_index('')\n",
        "\n",
        "df5.head()\n",
        "\n",
        "urlNHL6 = 'https://www.naturalstattrick.com/teamtable.php?fromseason=20222023&thruseason=20222023&stype=2&sit=pk&score=all&rate=y&team=all&loc=B&gpf=410&fd=&td='\n",
        "req6 = requests.get(urlNHL6)\n",
        "\n",
        "soup6 = BeautifulSoup(req6.content)\n",
        "\n",
        "top6 = list(soup6.children)\n",
        "\n",
        "body6 = soup6.find('body')\n",
        "\n",
        "body6.find_all('th')\n",
        "\n",
        "columns6 = [item.text for item in body6.find_all('th')]\n",
        "columns6\n",
        "\n",
        "body6.find_all('td')\n",
        "\n",
        "data6 = [e.text for e in body6.find_all('td')]\n",
        "\n",
        "start6 = 0\n",
        "table6 = []\n",
        "\n",
        "\n",
        "\n",
        "#loop through entire data\n",
        "\n",
        "while start6+len(columns6) <= len(data6):\n",
        "    player = []\n",
        "    #use length of columns as iteration stop point to get list of info for 1 player \n",
        "    for i in range(start6,start6+len(columns6)):\n",
        "        player.append(data6[i])\n",
        "    #add player row to list\n",
        "    table6.append(player)\n",
        "    #start at next player\n",
        "    start6 += len(columns6)\n",
        "\n",
        "df6 = pd.DataFrame(table6, columns = columns6, dtype = 'float').set_index('')\n",
        "\n",
        "df6.head()\n",
        "\n",
        "\n",
        "# Set up API keys and endpoint\n",
        "bearer_token = 'AAAAAAAAAAAAAAAAAAAAALipdwEAAAAAjEJzzmqWrvdlqLlu6XBTOxo%2Fjnc%3DyB7WhJ0vjDOJoano9MJFCO4s7R7aJTJuxjbU7tLGeoxSx9m4X3'\n",
        "odds_api_key = '8be3ba1d05ea7d3cda1d4ec6953e78c9'\n",
        "endpoint = 'https://api.twitter.com/2/tweets/search/recent'\n",
        "odds_endpoint = 'https://api.the-odds-api.com/v4/sports/icehockey_nhl/odds'\n",
        "\n",
        "\n",
        "# Get the odds for today's NHL games\n",
        "params = {\n",
        "    'regions': 'us',\n",
        "    'oddsFormat': 'decimal',\n",
        "    'dateFormat': 'iso',\n",
        "    'apiKey': odds_api_key,\n",
        "    'sport': 'icehockey_nhl',\n",
        "    'date': today, \n",
        "    'Markets' : 'h2h', \n",
        "    'Bookmakers' : 'bet365'\n",
        "}\n",
        "response_odds = requests.get(odds_endpoint, params=params)\n",
        "\n",
        "url = f\"https://statsapi.web.nhl.com/api/v1/schedule?date={today}&expand=schedule.linescore\"\n",
        "responseNHL = requests.get(url)\n",
        "dataNHL = responseNHL.json()\n",
        "\n",
        "\n",
        "\n",
        "# Set up API request\n",
        "url2 = 'https://statsapi.web.nhl.com/api/v1/schedule'\n",
        "paramsNHL = {\n",
        "    'startDate': '2022-03-01',\n",
        "    'endDate': '2022-03-31',\n",
        "    'expand': 'schedule.teams,schedule.linescore,schedule.broadcasts.all'\n",
        "}\n",
        "\n",
        "# Make API request\n",
        "responseNHL2 = requests.get(url2, params=paramsNHL)\n",
        "dataNHL2 = responseNHL2.json()['dates'][0]['games']\n",
        "# Analyser chaque équipe séparément\n",
        "\n",
        "for game in dataNHL['dates'][0]['games']:\n",
        "    home_team = game['teams']['home']['team']['name']\n",
        "    away_team = game['teams']['away']['team']['name']\n",
        "    team_df_H = df.loc[df['Team'] == home_team]\n",
        "    team_df_A = df.loc[df['Team'] == away_team]\n",
        "    team_df_H2 = df2.loc[df2['Team'] == home_team]\n",
        "    team_df_A2 = df2.loc[df2['Team'] == away_team]\n",
        "    team_df_H3 = df3.loc[df3['Team'] == home_team]\n",
        "    team_df_A3 = df3.loc[df3['Team'] == away_team]\n",
        "    team_df_H4 = df4.loc[df3['Team'] == home_team]\n",
        "    team_df_A4 = df4.loc[df3['Team'] == away_team]\n",
        "    team_df_H5 = df5.loc[df3['Team'] == home_team]\n",
        "    team_df_A5 = df5.loc[df3['Team'] == away_team]\n",
        "    team_df_H6 = df6.loc[df3['Team'] == home_team]\n",
        "    team_df_A6 = df6.loc[df3['Team'] == away_team]\n",
        "\n",
        "\n",
        "    try:\n",
        "      home_team.index('Canadiens')\n",
        "    except ValueError:\n",
        "      try:\n",
        "        home_team.index('Blues')\n",
        "      except ValueError:\n",
        "        team_df_H = df.loc[df['Team'] == home_team]\n",
        "      else:\n",
        "        team_df_H = df.loc[df['Team'] == 'St Louis Blues']\n",
        "    else:\n",
        "      team_df_H = df.loc[df['Team'] == 'Montreal Canadiens']\n",
        "      \n",
        "    try:\n",
        "        away_team.index('Canadiens')\n",
        "    except ValueError:\n",
        "        try:\n",
        "            away_team.index('Blues')\n",
        "        except ValueError:\n",
        "            team_df_A = df.loc[df['Team'] == away_team]\n",
        "        else:\n",
        "            team_df_A = df.loc[df['Team'] == 'St Louis Blues']\n",
        "    else:\n",
        "        team_df_A = df.loc[df['Team'] == 'Montreal Canadiens']\n",
        "    \n",
        "    try:\n",
        "      home_team.index('Canadiens')\n",
        "    except ValueError:\n",
        "      try:\n",
        "        home_team.index('Blues')\n",
        "      except ValueError:\n",
        "        team_df_H2 = df2.loc[df2['Team'] == home_team]\n",
        "      else:\n",
        "        team_df_H2 = df2.loc[df2['Team'] == 'St Louis Blues']\n",
        "    else:\n",
        "      team_df_H2 = df2.loc[df2['Team'] == 'Montreal Canadiens']\n",
        "      \n",
        "    try:\n",
        "        away_team.index('Canadiens')\n",
        "    except ValueError:\n",
        "        try:\n",
        "            away_team.index('Blues')\n",
        "        except ValueError:\n",
        "            team_df_A2 = df2.loc[df2['Team'] == away_team]\n",
        "        else:\n",
        "            team_df_A2 = df2.loc[df2['Team'] == 'St Louis Blues']\n",
        "    else:\n",
        "        team_df_A2 = df2.loc[df2['Team'] == 'Montreal Canadiens']\n",
        "\n",
        "    try:\n",
        "      home_team.index('Canadiens')\n",
        "    except ValueError:\n",
        "      try:\n",
        "        home_team.index('Blues')\n",
        "      except ValueError:\n",
        "        team_df_H3 = df3.loc[df3['Team'] == home_team]\n",
        "      else:\n",
        "        team_df_H3 = df3.loc[df3['Team'] == 'St Louis Blues']\n",
        "    else:\n",
        "      team_df_H3 = df3.loc[df3['Team'] == 'Montreal Canadiens']\n",
        "      \n",
        "    try:\n",
        "        away_team.index('Canadiens')\n",
        "    except ValueError:\n",
        "        try:\n",
        "            away_team.index('Blues')\n",
        "        except ValueError:\n",
        "            team_df_A3 = df3.loc[df3['Team'] == away_team]\n",
        "        else:\n",
        "            team_df_A3 = df3.loc[df3['Team'] == 'St Louis Blues']\n",
        "    else:\n",
        "        team_df_A3 = df3.loc[df3['Team'] == 'Montreal Canadiens']\n",
        "    \n",
        "    try:\n",
        "      home_team.index('Canadiens')\n",
        "    except ValueError:\n",
        "      try:\n",
        "        home_team.index('Blues')\n",
        "      except ValueError:\n",
        "        team_df_H4 = df4.loc[df4['Team'] == home_team]\n",
        "      else:\n",
        "        team_df_H4 = df4.loc[df4['Team'] == 'St Louis Blues']\n",
        "    else:\n",
        "      team_df_H4 = df4.loc[df4['Team'] == 'Montreal Canadiens']\n",
        "      \n",
        "    try:\n",
        "        away_team.index('Canadiens')\n",
        "    except ValueError:\n",
        "        try:\n",
        "            away_team.index('Blues')\n",
        "        except ValueError:\n",
        "            team_df_A4 = df4.loc[df4['Team'] == away_team]\n",
        "        else:\n",
        "            team_df_A4 = df4.loc[df4['Team'] == 'St Louis Blues']\n",
        "    else:\n",
        "        team_df_A4 = df4.loc[df4['Team'] == 'Montreal Canadiens']\n",
        "    \n",
        "    try:\n",
        "      home_team.index('Canadiens')\n",
        "    except ValueError:\n",
        "      try:\n",
        "        home_team.index('Blues')\n",
        "      except ValueError:\n",
        "        team_df_H5 = df5.loc[df5['Team'] == home_team]\n",
        "      else:\n",
        "        team_df_H5 = df5.loc[df5['Team'] == 'St Louis Blues']\n",
        "    else:\n",
        "      team_df_H5 = df5.loc[df5['Team'] == 'Montreal Canadiens']\n",
        "      \n",
        "    try:\n",
        "        away_team.index('Canadiens')\n",
        "    except ValueError:\n",
        "        try:\n",
        "            away_team.index('Blues')\n",
        "        except ValueError:\n",
        "            team_df_A5 = df5.loc[df5['Team'] == away_team]\n",
        "        else:\n",
        "            team_df_A5 = df5.loc[df5['Team'] == 'St Louis Blues']\n",
        "    else:\n",
        "        team_df_A5 = df5.loc[df5['Team'] == 'Montreal Canadiens']\n",
        "    \n",
        "    try:\n",
        "      home_team.index('Canadiens')\n",
        "    except ValueError:\n",
        "      try:\n",
        "        home_team.index('Blues')\n",
        "      except ValueError:\n",
        "        team_df_H6 = df6.loc[df6['Team'] == home_team]\n",
        "      else:\n",
        "        team_df_H6 = df6.loc[df6['Team'] == 'St Louis Blues']\n",
        "    else:\n",
        "      team_df_H6 = df6.loc[df6['Team'] == 'Montreal Canadiens']\n",
        "      \n",
        "    try:\n",
        "        away_team.index('Canadiens')\n",
        "    except ValueError:\n",
        "        try:\n",
        "            away_team.index('Blues')\n",
        "        except ValueError:\n",
        "            team_df_A6 = df6.loc[df6['Team'] == away_team]\n",
        "        else:\n",
        "            team_df_A6 = df6.loc[df6['Team'] == 'St Louis Blues']\n",
        "    else:\n",
        "        team_df_A6 = df6.loc[df6['Team'] == 'Montreal Canadiens']\n",
        "        \n",
        "\n",
        "    if response_odds.status_code == 200:\n",
        "      data_odds = response_odds.json()\n",
        "      for game in data_odds:\n",
        "        \n",
        "        away_team2 = game['away_team']\n",
        "        home_team2 = game['home_team']\n",
        "\n",
        "\n",
        "        \n",
        "        if game['bookmakers'][0]['markets'][0]['outcomes'][0]['name'] == home_team2 :\n",
        "          home_odds = game['bookmakers'][0]['markets'][0]['outcomes'][0]['price']\n",
        "        else:\n",
        "          home_odds = game['bookmakers'][0]['markets'][0]['outcomes'][1]['price']\n",
        "        \n",
        "        if game['bookmakers'][0]['markets'][0]['outcomes'][0]['name'] == away_team2 :\n",
        "          away_odds = game['bookmakers'][0]['markets'][0]['outcomes'][0]['price']\n",
        "        else:\n",
        "           away_odds = game['bookmakers'][0]['markets'][0]['outcomes'][1]['price']\n",
        "    else:\n",
        "      print(f\"Error getting odds: {response_odds.status_code}\")\n",
        "    \n",
        "    HDCF_A = team_df_A['HDCF/60'].values\n",
        "    HDCF_H = team_df_H['HDCF/60'].values\n",
        "    HDCA_A = team_df_A['HDCA/60'].values\n",
        "    HDCA_H = team_df_H['HDCA/60'].values\n",
        "\n",
        "    HDSH_A = (team_df_A4['HDGF/60'].values*100)/team_df_A4['HDCF/60'].values\n",
        "    HDSH_H = (team_df_H4['HDGF/60'].values*100)/team_df_H4['HDCF/60'].values\n",
        "\n",
        "    HDSV_A = 100 - ((team_df_A4['HDGA/60'].values*100)/team_df_A4['HDCA/60'].values)\n",
        "    HDSV_H = 100 - ((team_df_H4['HDGA/60'].values*100)/team_df_H4['HDCA/60'].values)\n",
        "\n",
        "    MDCF_A = team_df_A['MDCF/60'].values\n",
        "    MDCF_H = team_df_H['MDCF/60'].values\n",
        "    MDCA_A = team_df_A['MDCA/60'].values\n",
        "    MDCA_H = team_df_H['MDCA/60'].values\n",
        "\n",
        "    MDSH_A = (team_df_A4['MDGF/60'].values*100)/team_df_A4['MDCF/60'].values\n",
        "    MDSH_H = (team_df_H4['MDGF/60'].values*100)/team_df_H4['MDCF/60'].values\n",
        "\n",
        "    MDSV_A = 100 - ((team_df_A4['MDGA/60'].values*100)/team_df_A4['MDCA/60'].values)\n",
        "    MDSV_H = 100 - ((team_df_H4['MDGA/60'].values*100)/team_df_H4['MDCA/60'].values)\n",
        "\n",
        "    XGF_A = team_df_A['xGF/60'].values\n",
        "    XGF_H = team_df_H['xGF/60'].values\n",
        "\n",
        "    XGA_A = team_df_A['xGA/60'].values\n",
        "    XGA_H = team_df_H['xGA/60'].values\n",
        "\n",
        "    HDCF_A2 = team_df_A2['HDCF/60'].values\n",
        "    HDCF_H2 = team_df_H2['HDCF/60'].values\n",
        "    HDCA_A2 = team_df_A2['HDCA/60'].values\n",
        "    HDCA_H2 = team_df_H2['HDCA/60'].values\n",
        "\n",
        "    HDSH_A2 = weird_division((team_df_A5['HDGF/60'].values*100),team_df_A5['HDCF/60'].values)\n",
        "    HDSH_H2 = weird_division((team_df_H5['HDGF/60'].values*100),team_df_H5['HDCF/60'].values)\n",
        "\n",
        "    HDSV_A2 = 100 - weird_division((team_df_A5['HDGA/60'].values*100),team_df_A5['HDCA/60'].values)\n",
        "    HDSV_H2 = 100 - weird_division((team_df_H5['HDGA/60'].values*100),team_df_H5['HDCA/60'].values)\n",
        "\n",
        "    MDCF_A2 = team_df_A2['MDCF/60'].values\n",
        "    MDCF_H2 = team_df_H2['MDCF/60'].values\n",
        "    MDCA_A2 = team_df_A2['MDCA/60'].values\n",
        "    MDCA_H2 = team_df_H2['MDCA/60'].values\n",
        "\n",
        "    MDSH_A2 = weird_division((team_df_A5['MDGF/60'].values*100),team_df_A5['MDCF/60'].values)\n",
        "    MDSH_H2 = weird_division((team_df_H5['MDGF/60'].values*100),team_df_H5['MDCF/60'].values)\n",
        "\n",
        "    MDSV_A2 = 100 - weird_division((team_df_A5['MDGA/60'].values*100),team_df_A5['MDCA/60'].values)\n",
        "    MDSV_H2 = 100 - weird_division((team_df_H5['MDGA/60'].values*100),team_df_H5['MDCA/60'].values)\n",
        "\n",
        "    XGF_A2 = team_df_A2['xGF/60'].values\n",
        "    XGF_H2 = team_df_H2['xGF/60'].values\n",
        "\n",
        "    XGA_A2 = team_df_A2['xGA/60'].values\n",
        "    XGA_H2 = team_df_H2['xGA/60'].values\n",
        "\n",
        "    HDCF_A3 = team_df_A3['HDCF/60'].values\n",
        "    HDCF_H3 = team_df_H3['HDCF/60'].values\n",
        "    HDCA_A3 = team_df_A3['HDCA/60'].values\n",
        "    HDCA_H3 = team_df_H3['HDCA/60'].values\n",
        "\n",
        "    HDSH_A3 = weird_division((team_df_A6['HDGF/60'].values*100),team_df_A6['HDCF/60'].values)\n",
        "    HDSH_H3 = weird_division((team_df_H6['HDGF/60'].values*100),team_df_H6['HDCF/60'].values)\n",
        "\n",
        "    HDSV_A3 = 100 - weird_division((team_df_A6['HDGA/60'].values*100),team_df_A6['HDCA/60'].values)\n",
        "    HDSV_H3 = 100 - weird_division((team_df_H6['HDGA/60'].values*100),team_df_H6['HDCA/60'].values)\n",
        "\n",
        "    MDCF_A3 = team_df_A3['MDCF/60'].values\n",
        "    MDCF_H3 = team_df_H3['MDCF/60'].values\n",
        "    MDCA_A3 = team_df_A3['MDCA/60'].values\n",
        "    MDCA_H3 = team_df_H3['MDCA/60'].values\n",
        "\n",
        "    MDSH_A3 = weird_division((team_df_A6['MDGF/60'].values*100),team_df_A6['MDCF/60'].values)\n",
        "    MDSH_H3 = weird_division((team_df_H6['MDGF/60'].values*100),team_df_H6['MDCF/60'].values)\n",
        "\n",
        "    MDSV_A3 = 100 - weird_division((team_df_A6['MDGA/60'].values*100),team_df_A6['MDCA/60'].values)\n",
        "    MDSV_H3 = 100 - weird_division((team_df_H6['MDGA/60'].values*100),team_df_H6['MDCA/60'].values)\n",
        "\n",
        "    XGF_A3 = team_df_A3['xGF/60'].values\n",
        "    XGF_H3 = team_df_H3['xGF/60'].values\n",
        "\n",
        "    XGA_A3 = team_df_A3['xGA/60'].values\n",
        "    XGA_H3 = team_df_H3['xGA/60'].values\n",
        "    \n",
        "    time_array = team_df_A2['TOI/GP'].values\n",
        "    time_str = time_array.astype(str)\n",
        "    format_str = '%H:%M'\n",
        "    time_in_hours = []\n",
        "    for t in time_str:\n",
        "      datetime_obj = datetime.datetime.strptime(t, format_str)\n",
        "      time_in_hours.append(datetime_obj.hour + datetime_obj.minute/60)\n",
        "\n",
        "    time_array2 = team_df_H2['TOI/GP'].values\n",
        "    time_str2 = time_array2.astype(str)\n",
        "    format_str2 = '%H:%M'\n",
        "    time_in_hours2 = []\n",
        "    for t in time_str2:\n",
        "      datetime_obj = datetime.datetime.strptime(t, format_str2)\n",
        "      time_in_hours2.append(datetime_obj.hour + datetime_obj.minute/60)\n",
        "\n",
        "    time_array3 = team_df_A3['TOI/GP'].values\n",
        "    time_str3 = time_array3.astype(str)\n",
        "    format_str3 = '%H:%M'\n",
        "    time_in_hours3 = []\n",
        "    for t in time_str3:\n",
        "      datetime_obj = datetime.datetime.strptime(t, format_str3)\n",
        "      time_in_hours3.append(datetime_obj.hour + datetime_obj.minute/60)\n",
        "    \n",
        "    time_array4 = team_df_H3['TOI/GP'].values\n",
        "    time_str4 = time_array4.astype(str)\n",
        "    format_str4 = '%H:%M'\n",
        "    time_in_hours4 = []\n",
        "    for t in time_str4:\n",
        "      datetime_obj = datetime.datetime.strptime(t, format_str4)\n",
        "      time_in_hours4.append(datetime_obj.hour + datetime_obj.minute/60)\n",
        "    PP_A = sum(time_in_hours)\n",
        "    PP_H = sum(time_in_hours2)\n",
        "    PK_A = sum(time_in_hours3)\n",
        "    PK_H = sum(time_in_hours4)\n",
        "    PP_total_A = (PP_A + PK_H)/2\n",
        "    PP_total_H = (PP_H + PK_A)/2\n",
        "\n",
        "    score1_A = ((((HDCF_A + HDCA_H)/2)*(((HDSH_A+(100-HDSV_H))/2)/100)) + (((MDCF_A + MDCA_H)/2)*(((MDSH_A+(100-MDSV_H))/2)/100))) + ((((((HDCF_A2 + HDCA_H3)/2)*(((HDSH_A2+(100-HDSV_H3))/2)/100)) + (((MDCF_A2 + MDCA_H3)/2)*(((MDSH_A2+(100-MDSV_H3))/2)/100)))/60)*PP_total_A)\n",
        "    score1_H = ((((HDCF_H + HDCA_A)/2)*(((HDSH_H+(100-HDSV_A))/2)/100)) + (((MDCF_H + MDCA_A)/2)*(((MDSH_H+(100-MDSV_A))/2)/100))) + ((((((HDCF_H2 + HDCA_A3)/2)*(((HDSH_H2+(100-HDSV_A3))/2)/100)) + (((MDCF_H2 + MDCA_A3)/2)*(((MDSH_H2+(100-MDSV_A3))/2)/100)))/60)*PP_total_H)\n",
        "    score2_A = ((XGF_A + XGA_H)/2) + ((((XGF_A2 + XGA_H3)/2)/60)*PP_total_A)\n",
        "    score2_H = ((XGF_H + XGA_A)/2) + ((((XGF_H2 + XGA_A3)/2)/60)*PP_total_H)\n",
        "\n",
        "    pred_A = (score1_A + score2_A)/2\n",
        "    pred_H = (score1_H + score2_H)/2\n",
        "\n",
        "    pred_total = pred_A+pred_H\n",
        "    imp_odds_A = (pred_A / pred_total)*100\n",
        "    imp_odds_B = (pred_H / pred_total)*100\n",
        "\n",
        "    print(f\"{away_team} vs {home_team}:\")\n",
        "    print(\"Score_A :\", pred_A, \"Win%:\", imp_odds_A)\n",
        "    print(\"Score_H :\", pred_H, \"Win%:\", imp_odds_B)\n",
        "    print(\"Total:\", pred_total)\n",
        "\n",
        "    query_str_H = f\"{home_team} OR {home_team.lower()} OR {home_team.upper()}\"\n",
        "    query_str_A = f\"{away_team} OR {away_team.lower()} OR {away_team.upper()}\"\n",
        "\n",
        "    params_H = {\n",
        "        'query': query_str_H,\n",
        "        'max_results': 50,\n",
        "        'tweet.fields': 'public_metrics',\n",
        "        'expansions': 'author_id',\n",
        "        'user.fields': 'username'\n",
        "    }\n",
        "    \n",
        "    params_A = {\n",
        "        'query': query_str_A,\n",
        "        'max_results': 50,\n",
        "        'tweet.fields': 'public_metrics',\n",
        "        'expansions': 'author_id',\n",
        "        'user.fields': 'username'\n",
        "    }\n",
        "\n",
        "    # Set up headers and make request\n",
        "    headers = {'Authorization': f'Bearer {bearer_token}'}\n",
        "    response_A = requests.get(endpoint, headers=headers, params=params_A)\n",
        "    response_H = requests.get(endpoint, headers=headers, params=params_H)\n",
        "\n",
        "    def clean_tweet_text(tweet):\n",
        "        # Remove URLs, RTs, and hashtags from the tweet text\n",
        "        cleaned_tweet = re.sub(r\"http\\S+|RT|@\\S+|#\\S+\", \"\", tweet)\n",
        "        return cleaned_tweet.strip()\n",
        "\n",
        "    # Parse JSON response and analyze sentiment of each tweet\n",
        "    positive_tweets = 0\n",
        "    negative_tweets = 0\n",
        "\n",
        "    if response_A.status_code == 200:\n",
        "        data = response_A.json()\n",
        "        for tweet in data['data']:\n",
        "            text = clean_tweet_text(tweet['text'])\n",
        "            blob = TextBlob(text)\n",
        "            sentiment = blob.sentiment.polarity\n",
        "            subjectivity = blob.sentiment.subjectivity\n",
        "            if sentiment > 0.0:\n",
        "                positive_tweets += 1\n",
        "            elif sentiment < 0.0:\n",
        "                negative_tweets += 1\n",
        "\n",
        "        total_tweets = positive_tweets + negative_tweets\n",
        "        if total_tweets > 0:\n",
        "          ratio = positive_tweets / total_tweets\n",
        "        print(\"Twitter_A :\", ratio*100, \"%\")\n",
        "    else:\n",
        "        print(f\"Error: {response_A.status_code}\")\n",
        "    \n",
        "    if response_H.status_code == 200:\n",
        "        data = response_H.json()\n",
        "        for tweet in data['data']:\n",
        "            text = clean_tweet_text(tweet['text'])\n",
        "            blob = TextBlob(text)\n",
        "            sentiment = blob.sentiment.polarity\n",
        "            subjectivity = blob.sentiment.subjectivity\n",
        "            if sentiment > 0.0:\n",
        "                positive_tweets += 1\n",
        "            elif sentiment < 0.0:\n",
        "                negative_tweets += 1\n",
        "\n",
        "        total_tweets = positive_tweets + negative_tweets\n",
        "        if total_tweets > 0:\n",
        "          ratio = positive_tweets / total_tweets\n",
        "        print(\"Twitter_H :\", ratio*100, \"%\")\n",
        "    else:\n",
        "        print(f\"Error: {response_H.status_code}\")\n"
      ]
    }
  ]
}